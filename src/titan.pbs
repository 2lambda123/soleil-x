#!/bin/bash -eu
#PBS -A CSC188
#PBS -N soleil

# Set the umask to something reasonable.
umask 022

# First switch to the directory where this job was launched, to make sure
# any relative paths in the arguments are valid.
cd "$PBS_O_WORKDIR"

# Create a directory on the scratch filesystem, for output (if the user hasn't
# specified an output directory explicitly).
OUT_DIR=
OUT_DIR_FOLLOWS=false
for ARG in $ARGS; do
    if [[ "$OUT_DIR_FOLLOWS" == true ]]; then
        OUT_DIR="$ARG"
        break
    elif [[ "$ARG" == "-o" ]]; then
        OUT_DIR_FOLLOWS=true
    fi
done
if [[ -z "$OUT_DIR" ]]; then
    OUT_DIR="$PROJWORK"/csc188/stanford/"$PBS_JOBID"
    mkdir "$OUT_DIR"
    ARGS="$ARGS -o $OUT_DIR"
    echo "Redirecting output to $OUT_DIR"
fi

# Process CUDA configuration
NUM_THREADS=8
GPU_OPTS=
if [[ "$USE_CUDA" == 1 ]]; then
    NUM_THREADS=7
    GPU_OPTS="-ll:gpu 1 -ll:fsize 5120"
fi

# NOTE: LLVM installs a bad ELF interpreter on the executable, so we run it
# through ld.so.
aprun -n "$NUM_RANKS" -N 1 -cc none \
    /lib64/ld-linux-x86-64.so.2 \
    "$SOLEIL_DIR"/src/soleil.exec $ARGS $GPU_OPTS \
    -ll:cpu 0 -ll:ocpu 1 -ll:onuma 0 -ll:okindhack -ll:othr "$NUM_THREADS" \
    -ll:csize 25000 -ll:rsize 1024 -ll:gsize 0 -ll:ostack 8

# Resources:
# 32GB RAM per node
# 2 NUMA domains per node
# 4 core pairs with shared FP unit per NUMA domain
# 1 Kepler K20X GPU per node
# 6GB FB per GPU
